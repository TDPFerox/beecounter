# ğŸ BeeCounter - Dichtekarten-basierte BienenzÃ¤hlung

Dieses Projekt nutzt ein **U-Net (Convolutional Neural Network)**, um Bienen auf hochauflÃ¶senden Wabenbildern zu lokalisieren und zu zÃ¤hlen. Statt einer Klassifizierung generiert das Modell eine **Dichtekarte (Density Map)**, die eine prÃ¤zise rÃ¤umliche Verteilung der Bienen ermÃ¶glicht.

## ğŸš€ Features
* **U-Net Architektur:** Symmetrischer Encoder-Decoder-Pfad fÃ¼r hochauflÃ¶sende Merkmalsextraktion.
* **RAM-schonendes Streaming:** Ein spezialisierter `BeeDataGenerator` lÃ¤dt Daten batchweise von der Festplatte, was das Training mit Ã¼ber 70.000 Kacheln auf Consumer-Hardware ermÃ¶glicht.
* **Kombinierter Loss:** Optimierung Ã¼ber Pixel-Dichte (MSE) und absolute ZÃ¤hlgenauigkeit (Count Loss).
* **Kontinuierliches Training:** Automatisches Speichern des besten Modells (`best_model.keras`) und Logging der Historie in einer CSV-Datei.

## ğŸ“‚ Projektstruktur
* `workflow.py`: Zentrales Steuerungsskript fÃ¼r Datenvorbereitung und Training.
* `model.py`: Definition des U-Nets, der Loss-Funktionen und des Daten-Generators.
* `prepare_data.py`: Skript zur Kachelung (Tiling) und Augmentation der Rohbilder.
* `training_log.csv`: CSV-Protokoll aller Trainingsmetriken pro Epoche.

ZusÃ¤tzlich existieren Skripte zur Generierung von Metriken und dem Predicten von unbekannten Testdaten.
Diese sind alle unter Src zu finden.

Im Bereich Modell sind die aktuellen mit meinen Trainingsdaten trainierten Modelle zu finden. Unter Metric finden sich Daten und Bilder von TrainingslÃ¤ufen und Predictions.

## Aktueller Trainingslauf

![Trainingshistorie](/Metric/training_history.png)

Epoche 0 wurde hier abgeschnitten, da der Loss in der ersten Epoche so hoch war, das die nachfolgenden Epochen durch die Skalierung nicht mehr lesbar waren.

## ğŸ›  Installation & Setup

1.  **Umgebung einrichten:**
    ```bash
    python3 -m venv .venv
    source .venv/bin/activate
    pip install tensorflow pandas matplotlib opencv-python
    ```

2.  **Daten vorbereiten:**
    Um selber zu trainieren, mÃ¼ssen die Testdaten selbst zur VerfÃ¼gung gestellt werden. Die Trainingsdaten mÃ¼ssen in einem Ordner Data abgelegt werden. Bilder kommen dabei in einen Ordner Data/Wabenbilder und die XML Dateien mit den Koordinaten fÃ¼r die Dichtekarten unter Data/annotations. Aktuell kÃ¶nnen nur Annotations basierend auf dem Format CVAT for images 1.1 eingelesen werden.

## ğŸ“ˆ Training ausfÃ¼hren

Starte den gesamten Prozess Ã¼ber die `workflow.py`:
```bash
python3 workflow.py